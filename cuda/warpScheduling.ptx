//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Mar 14 00:01:35 2014 (1394735495)
// Cuda compilation tools, release 6.0, V6.0.1
//

.version 4.0
.target sm_20
.address_size 64


.visible .func  (.param .b32 func_retval0) _Z8get_smidv(

)
{
	.reg .s32 	%r<2>;


	// inline asm
	mov.u32 %r1, %smid;
	// inline asm
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

.visible .func _Z21recursively_divergentPiS_S_(
	.param .b64 _Z21recursively_divergentPiS_S__param_0,
	.param .b64 _Z21recursively_divergentPiS_S__param_1,
	.param .b64 _Z21recursively_divergentPiS_S__param_2
)
{
	.reg .pred 	%p<26>;
	.reg .s32 	%r<46>;
	.reg .s64 	%rd<10>;


	ld.param.u64 	%rd6, [_Z21recursively_divergentPiS_S__param_0];
	ld.param.u64 	%rd7, [_Z21recursively_divergentPiS_S__param_1];
	ld.param.u64 	%rd8, [_Z21recursively_divergentPiS_S__param_2];
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %tid.z;
	mov.u32 	%r7, %nctaid.y;
	mov.u32 	%r8, %ctaid.y;
	mad.lo.s32 	%r9, %r7, %r6, %r8;
	mov.u32 	%r10, %ctaid.x;
	mad.lo.s32 	%r11, %r9, %r5, %r10;
	mov.u32 	%r12, %ntid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r11, %r12, %r13;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r1, %r14, %r15, %r16;
	bar.sync 	0;
	add.s64 	%rd2, %rd8, 4;
	mul.wide.s32 	%rd9, %r1, 4;
	add.s64 	%rd4, %rd6, %rd9;
	shr.s32 	%r18, %r1, 31;
	shr.u32 	%r19, %r18, 27;
	add.s32 	%r20, %r1, %r19;
	shr.s32 	%r2, %r20, 5;
	add.s64 	%rd5, %rd7, %rd9;
	mov.u32 	%r45, 0;

BB1_1:
	setp.eq.s32	%p1, %r1, 31;
	@%p1 bra 	BB1_3;

	ld.u32 	%r21, [%rd8+4];
	setp.ne.s32	%p2, %r1, %r21;
	@%p2 bra 	BB1_7;

BB1_3:
	@%p1 bra 	BB1_5;

	atom.add.u32 	%r22, [%rd2], 1;
	st.u32 	[%rd4], %r22;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_6;

BB1_5:
	ld.u32 	%r23, [%rd8+4];
	st.u32 	[%rd6+124], %r23;

BB1_6:
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 0

BB1_7:
	@%p1 bra 	BB1_9;

	ld.u32 	%r24, [%rd8+4];
	setp.ne.s32	%p5, %r1, %r24;
	@%p5 bra 	BB1_13;

BB1_9:
	@%p1 bra 	BB1_11;

	atom.add.u32 	%r25, [%rd2], 1;
	st.u32 	[%rd4], %r25;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_12;

BB1_11:
	ld.u32 	%r26, [%rd8+4];
	st.u32 	[%rd6+124], %r26;

BB1_12:
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 1

BB1_13:
	@%p1 bra 	BB1_15;

	ld.u32 	%r27, [%rd8+4];
	setp.ne.s32	%p8, %r1, %r27;
	@%p8 bra 	BB1_19;

BB1_15:
	@%p1 bra 	BB1_17;

	atom.add.u32 	%r28, [%rd2], 1;
	st.u32 	[%rd4], %r28;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_18;

BB1_17:
	ld.u32 	%r29, [%rd8+4];
	st.u32 	[%rd6+124], %r29;

BB1_18:
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 2

BB1_19:
	@%p1 bra 	BB1_21;

	ld.u32 	%r30, [%rd8+4];
	setp.ne.s32	%p11, %r1, %r30;
	@%p11 bra 	BB1_25;

BB1_21:
	@%p1 bra 	BB1_23;

	atom.add.u32 	%r31, [%rd2], 1;
	st.u32 	[%rd4], %r31;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_24;

BB1_23:
	ld.u32 	%r32, [%rd8+4];
	st.u32 	[%rd6+124], %r32;

BB1_24:
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 3

BB1_25:
	@%p1 bra 	BB1_27;

	ld.u32 	%r33, [%rd8+4];
	setp.ne.s32	%p14, %r1, %r33;
	@%p14 bra 	BB1_31;

BB1_27:
	@%p1 bra 	BB1_29;

	atom.add.u32 	%r34, [%rd2], 1;
	st.u32 	[%rd4], %r34;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_30;

BB1_29:
	ld.u32 	%r35, [%rd8+4];
	st.u32 	[%rd6+124], %r35;

BB1_30:
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 4

BB1_31:
	@%p1 bra 	BB1_33;

	ld.u32 	%r36, [%rd8+4];
	setp.ne.s32	%p17, %r1, %r36;
	@%p17 bra 	BB1_37;

BB1_33:
	@%p1 bra 	BB1_35;

	atom.add.u32 	%r37, [%rd2], 1;
	st.u32 	[%rd4], %r37;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_36;

BB1_35:
	ld.u32 	%r38, [%rd8+4];
	st.u32 	[%rd6+124], %r38;

BB1_36:
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 5

BB1_37:
	@%p1 bra 	BB1_39;

	ld.u32 	%r39, [%rd8+4];
	setp.ne.s32	%p20, %r1, %r39;
	@%p20 bra 	BB1_43;

BB1_39:
	@%p1 bra 	BB1_41;

	atom.add.u32 	%r40, [%rd2], 1;
	st.u32 	[%rd4], %r40;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_42;

BB1_41:
	ld.u32 	%r41, [%rd8+4];
	st.u32 	[%rd6+124], %r41;

BB1_42:
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 6

BB1_43:
	@%p1 bra 	BB1_45;

	ld.u32 	%r42, [%rd8+4];
	setp.ne.s32	%p23, %r1, %r42;
	@%p23 bra 	BB1_49;

BB1_45:
	@%p1 bra 	BB1_47;

	atom.add.u32 	%r43, [%rd2], 1;
	st.u32 	[%rd4], %r43;
	st.u32 	[%rd5], %r2;
	bra.uni 	BB1_48;

BB1_47:
	ld.u32 	%r44, [%rd8+4];
	st.u32 	[%rd6+124], %r44;

BB1_48:
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd7;
	.param .b64 param2;
	st.param.b64	[param2+0], %rd8;
	call.uni 
	_Z21recursively_divergentPiS_S_, 
	(
	param0, 
	param1, 
	param2
	);
	}
	// Callseq End 7

BB1_49:
	add.s32 	%r45, %r45, 8;
	setp.ne.s32	%p25, %r45, 32;
	@%p25 bra 	BB1_1;

	ret;
}

.visible .entry _Z14full_divergentPiS_S_(
	.param .u64 _Z14full_divergentPiS_S__param_0,
	.param .u64 _Z14full_divergentPiS_S__param_1,
	.param .u64 _Z14full_divergentPiS_S__param_2
)
{
	.reg .pred 	%p<34>;
	.reg .s32 	%r<45>;
	.reg .s64 	%rd<11>;


	ld.param.u64 	%rd7, [_Z14full_divergentPiS_S__param_0];
	ld.param.u64 	%rd9, [_Z14full_divergentPiS_S__param_1];
	ld.param.u64 	%rd8, [_Z14full_divergentPiS_S__param_2];
	cvta.to.global.u64 	%rd1, %rd9;
	mov.u32 	%r5, %tid.z;
	mov.u32 	%r6, %nctaid.y;
	mov.u32 	%r7, %ctaid.y;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %nctaid.x;
	mov.u32 	%r10, %ctaid.x;
	mad.lo.s32 	%r11, %r8, %r9, %r10;
	mov.u32 	%r12, %ntid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r11, %r12, %r13;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r1, %r14, %r15, %r16;
	bar.sync 	0;
	cvta.to.global.u64 	%rd2, %rd8;
	add.s64 	%rd3, %rd2, 4;
	cvta.to.global.u64 	%rd4, %rd7;
	mul.wide.s32 	%rd10, %r1, 4;
	add.s64 	%rd5, %rd4, %rd10;
	shr.s32 	%r18, %r1, 31;
	shr.u32 	%r19, %r18, 27;
	add.s32 	%r20, %r1, %r19;
	shr.s32 	%r2, %r20, 5;
	add.s64 	%rd6, %rd1, %rd10;
	mov.u32 	%r44, 0;

BB2_1:
	setp.ne.s32	%p1, %r44, %r1;
	setp.ne.s32	%p2, %r1, 31;
	and.pred  	%p3, %p2, %p1;
	@%p3 bra 	BB2_5;

	setp.eq.s32	%p4, %r1, 31;
	@%p4 bra 	BB2_4;

	atom.global.add.u32 	%r21, [%rd3], 1;
	st.global.u32 	[%rd5], %r21;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_5;

BB2_4:
	ld.global.u32 	%r22, [%rd2+4];
	st.global.u32 	[%rd4+124], %r22;

BB2_5:
	add.s32 	%r23, %r44, 1;
	setp.ne.s32	%p6, %r23, %r1;
	and.pred  	%p7, %p2, %p6;
	@%p7 bra 	BB2_9;

	setp.eq.s32	%p8, %r1, 31;
	@%p8 bra 	BB2_8;

	atom.global.add.u32 	%r24, [%rd3], 1;
	st.global.u32 	[%rd5], %r24;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_9;

BB2_8:
	ld.global.u32 	%r25, [%rd2+4];
	st.global.u32 	[%rd4+124], %r25;

BB2_9:
	add.s32 	%r26, %r44, 2;
	setp.ne.s32	%p10, %r26, %r1;
	and.pred  	%p11, %p2, %p10;
	@%p11 bra 	BB2_13;

	setp.eq.s32	%p12, %r1, 31;
	@%p12 bra 	BB2_12;

	atom.global.add.u32 	%r27, [%rd3], 1;
	st.global.u32 	[%rd5], %r27;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_13;

BB2_12:
	ld.global.u32 	%r28, [%rd2+4];
	st.global.u32 	[%rd4+124], %r28;

BB2_13:
	add.s32 	%r29, %r44, 3;
	setp.ne.s32	%p14, %r29, %r1;
	and.pred  	%p15, %p2, %p14;
	@%p15 bra 	BB2_17;

	setp.eq.s32	%p16, %r1, 31;
	@%p16 bra 	BB2_16;

	atom.global.add.u32 	%r30, [%rd3], 1;
	st.global.u32 	[%rd5], %r30;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_17;

BB2_16:
	ld.global.u32 	%r31, [%rd2+4];
	st.global.u32 	[%rd4+124], %r31;

BB2_17:
	add.s32 	%r32, %r44, 4;
	setp.ne.s32	%p18, %r32, %r1;
	and.pred  	%p19, %p2, %p18;
	@%p19 bra 	BB2_21;

	setp.eq.s32	%p20, %r1, 31;
	@%p20 bra 	BB2_20;

	atom.global.add.u32 	%r33, [%rd3], 1;
	st.global.u32 	[%rd5], %r33;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_21;

BB2_20:
	ld.global.u32 	%r34, [%rd2+4];
	st.global.u32 	[%rd4+124], %r34;

BB2_21:
	add.s32 	%r35, %r44, 5;
	setp.ne.s32	%p22, %r35, %r1;
	and.pred  	%p23, %p2, %p22;
	@%p23 bra 	BB2_25;

	setp.eq.s32	%p24, %r1, 31;
	@%p24 bra 	BB2_24;

	atom.global.add.u32 	%r36, [%rd3], 1;
	st.global.u32 	[%rd5], %r36;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_25;

BB2_24:
	ld.global.u32 	%r37, [%rd2+4];
	st.global.u32 	[%rd4+124], %r37;

BB2_25:
	add.s32 	%r38, %r44, 6;
	setp.ne.s32	%p26, %r38, %r1;
	and.pred  	%p27, %p2, %p26;
	@%p27 bra 	BB2_29;

	setp.eq.s32	%p28, %r1, 31;
	@%p28 bra 	BB2_28;

	atom.global.add.u32 	%r39, [%rd3], 1;
	st.global.u32 	[%rd5], %r39;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_29;

BB2_28:
	ld.global.u32 	%r40, [%rd2+4];
	st.global.u32 	[%rd4+124], %r40;

BB2_29:
	add.s32 	%r41, %r44, 7;
	setp.ne.s32	%p30, %r41, %r1;
	and.pred  	%p31, %p2, %p30;
	@%p31 bra 	BB2_33;

	setp.eq.s32	%p32, %r1, 31;
	@%p32 bra 	BB2_32;

	atom.global.add.u32 	%r42, [%rd3], 1;
	st.global.u32 	[%rd5], %r42;
	st.global.u32 	[%rd6], %r2;
	bra.uni 	BB2_33;

BB2_32:
	ld.global.u32 	%r43, [%rd2+4];
	st.global.u32 	[%rd4+124], %r43;

BB2_33:
	add.s32 	%r44, %r44, 8;
	setp.ne.s32	%p33, %r44, 32;
	@%p33 bra 	BB2_1;

	ret;
}

.visible .entry _Z14zero_divergentPiS_(
	.param .u64 _Z14zero_divergentPiS__param_0,
	.param .u64 _Z14zero_divergentPiS__param_1
)
{
	.reg .s32 	%r<16>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z14zero_divergentPiS__param_0];
	mov.u32 	%r2, %nctaid.x;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %nctaid.y;
	mov.u32 	%r5, %ntid.y;
	mov.u32 	%r6, %tid.z;
	mov.u32 	%r7, %ctaid.y;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.y;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r11, %r4, %r6, %r7;
	mad.lo.s32 	%r12, %r11, %r2, %r8;
	mad.lo.s32 	%r13, %r12, %r5, %r9;
	mad.lo.s32 	%r14, %r13, %r3, %r10;
	cvta.to.global.u64 	%rd2, %rd1;
	// inline asm
	mov.u32 %r1, %smid;
	// inline asm
	add.s32 	%r15, %r1, 99;
	mul.wide.s32 	%rd3, %r14, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.u32 	[%rd4], %r15;
	ret;
}


